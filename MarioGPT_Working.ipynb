{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MarioGPT Level Generation, Visualization, and Evaluation\n",
    "\n",
    "This notebook demonstrates the complete workflow for generating, visualizing, and evaluating Mario levels using the MarioGPT project with the actual LevelGenerator class.\n",
    "\n",
    "## Workflow Overview\n",
    "1. **Imports and Setup**: Load necessary libraries and initialize the level generator\n",
    "2. **Level Generation**: Generate procedurally-created Mario levels\n",
    "3. **Visualization**: Display the generated levels\n",
    "4. **Evaluation**: Assess level properties and playability\n",
    "5. **Analysis**: Analyze and compare different generated levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "# Import the LevelGenerator class\n",
    "from level_generator import LevelGenerator\n",
    "\n",
    "print(\"‚úì Imports successful!\")\n",
    "print(f\"‚úì Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the Level Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LevelGenerator with default parameters\n",
    "generator = LevelGenerator(\n",
    "    width=50,           # Level width (in tiles)\n",
    "    height=16,          # Level height (in tiles)\n",
    "    seed=42             # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "print(\"‚úì LevelGenerator initialized successfully!\")\n",
    "print(f\"  - Level dimensions: {generator.width}x{generator.height} tiles\")\n",
    "print(f\"  - Tile size: {generator.tile_size}x{generator.tile_size} pixels (standard)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Mario Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple levels with different seeds for variety\n",
    "num_levels = 3\n",
    "levels = []\n",
    "\n",
    "for i in range(num_levels):\n",
    "    level = generator.generate(seed=42 + i)\n",
    "    levels.append(level)\n",
    "    print(f\"‚úì Generated Level {i+1}\")\n",
    "    print(f\"  - Shape: {level.shape}\")\n",
    "    print(f\"  - Unique tiles: {np.unique(level)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tile Legend and Visualization Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tile types and their color mappings\n",
    "tile_colors = {\n",
    "    0: (1.0, 1.0, 1.0),        # Empty/Air - White\n",
    "    1: (0.4, 0.2, 0.0),        # Ground - Brown\n",
    "    2: (1.0, 0.84, 0.0),       # Coin - Gold/Yellow\n",
    "    3: (1.0, 0.0, 0.0),        # Obstacle/Enemy - Red\n",
    "    4: (0.0, 0.5, 0.0),        # Platform - Green\n",
    "    5: (0.5, 0.5, 0.5),        # Box - Gray\n",
    "}\n",
    "\n",
    "tile_names = {\n",
    "    0: 'Air',\n",
    "    1: 'Ground',\n",
    "    2: 'Coin',\n",
    "    3: 'Obstacle',\n",
    "    4: 'Platform',\n",
    "    5: 'Box',\n",
    "}\n",
    "\n",
    "def get_tile_color(tile_value):\n",
    "    \"\"\"Get RGB color for a tile value\"\"\"\n",
    "    return tile_colors.get(tile_value, (0.0, 0.0, 0.0))\n",
    "\n",
    "print(\"‚úì Tile legend created\")\n",
    "print(\"\\nTile Types:\")\n",
    "for tile_id, tile_name in sorted(tile_names.items()):\n",
    "    print(f\"  {tile_id}: {tile_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Generated Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_level(level, title=\"Mario Level\", figsize=(16, 5)):\n",
    "    \"\"\"\n",
    "    Visualize a single Mario level with proper coloring\n",
    "    \n",
    "    Parameters:\n",
    "    - level: 2D numpy array representing the level\n",
    "    - title: Title for the visualization\n",
    "    - figsize: Figure size (width, height)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    # Create RGB image from level data\n",
    "    height, width = level.shape\n",
    "    image = np.zeros((height, width, 3))\n",
    "    \n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            image[h, w, :] = get_tile_color(level[h, w])\n",
    "    \n",
    "    # Display the level (flip vertically so ground is at bottom)\n",
    "    ax.imshow(np.flipud(image), aspect='auto', interpolation='nearest')\n",
    "    \n",
    "    # Add grid\n",
    "    ax.set_xticks(np.arange(-0.5, width, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, height, 1), minor=True)\n",
    "    ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    ax.set_xlabel('X Position (tiles)', fontsize=12)\n",
    "    ax.set_ylabel('Y Position (tiles)', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "# Visualize all generated levels\n",
    "for idx, level in enumerate(levels):\n",
    "    visualize_level(level, title=f\"Generated Mario Level {idx+1}\")\n",
    "    plt.show()\n",
    "    print(f\"‚úì Level {idx+1} visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Level Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_level(level, level_id=1):\n",
    "    \"\"\"\n",
    "    Evaluate various properties of a generated level\n",
    "    \n",
    "    Parameters:\n",
    "    - level: 2D numpy array representing the level\n",
    "    - level_id: Identifier for the level\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'level_id': level_id,\n",
    "        'dimensions': level.shape,\n",
    "        'total_tiles': level.size,\n",
    "    }\n",
    "    \n",
    "    # Count tile occurrences\n",
    "    unique, counts = np.unique(level, return_counts=True)\n",
    "    tile_counts = dict(zip(unique, counts))\n",
    "    \n",
    "    # Calculate percentages for each tile type\n",
    "    metrics['tile_distribution'] = {}\n",
    "    for tile_id in sorted(tile_names.keys()):\n",
    "        count = tile_counts.get(tile_id, 0)\n",
    "        percentage = (count / level.size) * 100\n",
    "        metrics['tile_distribution'][tile_names[tile_id]] = {\n",
    "            'count': count,\n",
    "            'percentage': percentage\n",
    "        }\n",
    "    \n",
    "    # Structural analysis\n",
    "    metrics['ground_tiles'] = tile_counts.get(1, 0)\n",
    "    metrics['coins'] = tile_counts.get(2, 0)\n",
    "    metrics['obstacles'] = tile_counts.get(3, 0)\n",
    "    metrics['platforms'] = tile_counts.get(4, 0)\n",
    "    metrics['boxes'] = tile_counts.get(5, 0)\n",
    "    metrics['air_tiles'] = tile_counts.get(0, 0)\n",
    "    \n",
    "    # Playability metrics\n",
    "    metrics['solid_tile_density'] = (\n",
    "        (metrics['ground_tiles'] + metrics['platforms'] + metrics['boxes']) / level.size\n",
    "    ) * 100\n",
    "    metrics['collectible_ratio'] = (\n",
    "        metrics['coins'] / max(1, level.size) * 100\n",
    "    )\n",
    "    metrics['challenge_ratio'] = (\n",
    "        metrics['obstacles'] / max(1, level.size) * 100\n",
    "    )\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Evaluate all levels\n",
    "evaluations = []\n",
    "for idx, level in enumerate(levels):\n",
    "    metrics = evaluate_level(level, level_id=idx+1)\n",
    "    evaluations.append(metrics)\n",
    "\n",
    "print(\"‚úì Level evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Display Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_level_report(metrics):\n",
    "    \"\"\"\n",
    "    Print a formatted report of level evaluation metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LEVEL {metrics['level_id']} EVALUATION REPORT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nüìê LEVEL DIMENSIONS:\")\n",
    "    print(f\"   Height: {metrics['dimensions'][0]} tiles\")\n",
    "    print(f\"   Width: {metrics['dimensions'][1]} tiles\")\n",
    "    print(f\"   Total Tiles: {metrics['total_tiles']}\")\n",
    "    \n",
    "    print(f\"\\nüéÆ TILE DISTRIBUTION:\")\n",
    "    for tile_name, data in metrics['tile_distribution'].items():\n",
    "        count = data['count']\n",
    "        percentage = data['percentage']\n",
    "        bar = '‚ñà' * int(percentage / 2)\n",
    "        print(f\"   {tile_name:12} {count:4} tiles ({percentage:5.1f}%) {bar}\")\n",
    "    \n",
    "    print(f\"\\nüèóÔ∏è  STRUCTURAL ANALYSIS:\")\n",
    "    print(f\"   Ground Tiles:      {metrics['ground_tiles']:4} tiles\")\n",
    "    print(f\"   Platforms:         {metrics['platforms']:4} tiles\")\n",
    "    print(f\"   Boxes:             {metrics['boxes']:4} tiles\")\n",
    "    print(f\"   Air Space:         {metrics['air_tiles']:4} tiles\")\n",
    "    \n",
    "    print(f\"\\nüé≤ PLAYABILITY METRICS:\")\n",
    "    print(f\"   Solid Tile Density: {metrics['solid_tile_density']:.1f}%\")\n",
    "    print(f\"   Collectible Ratio:  {metrics['collectible_ratio']:.1f}%\")\n",
    "    print(f\"   Challenge Ratio:    {metrics['challenge_ratio']:.1f}%\")\n",
    "    print(f\"   Coins to Collect:   {metrics['coins']}\")\n",
    "    print(f\"   Obstacles to Avoid: {metrics['obstacles']}\")\n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "# Print reports for all levels\n",
    "for metrics in evaluations:\n",
    "    print_level_report(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a comparative analysis dataframe\n",
    "comparison_data = []\n",
    "for metrics in evaluations:\n",
    "    comparison_data.append({\n",
    "        'Level': metrics['level_id'],\n",
    "        'Ground %': metrics['tile_distribution']['Ground']['percentage'],\n",
    "        'Coins %': metrics['tile_distribution']['Coin']['percentage'],\n",
    "        'Obstacles %': metrics['tile_distribution']['Obstacle']['percentage'],\n",
    "        'Platforms %': metrics['tile_distribution']['Platform']['percentage'],\n",
    "        'Air %': metrics['tile_distribution']['Air']['percentage'],\n",
    "        'Solid Density': metrics['solid_tile_density'],\n",
    "        'Challenge': metrics['challenge_ratio'],\n",
    "        'Collectibles': metrics['collectible_ratio'],\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\nüìä COMPARATIVE ANALYSIS\\n\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Display statistics\n",
    "print(\"\\nüìà STATISTICS ACROSS ALL LEVELS\\n\")\n",
    "numeric_cols = df_comparison.select_dtypes(include=[np.number]).columns\n",
    "stats_df = df_comparison[numeric_cols].describe()\n",
    "print(stats_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualization Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Tile Distribution Comparison\n",
    "ax1 = axes[0, 0]\n",
    "tile_types = ['Ground', 'Coins', 'Obstacles', 'Platforms', 'Air']\n",
    "x = np.arange(len(tile_types))\n",
    "width = 0.25\n",
    "\n",
    "for i, metrics in enumerate(evaluations):\n",
    "    values = [\n",
    "        metrics['tile_distribution']['Ground']['percentage'],\n",
    "        metrics['tile_distribution']['Coin']['percentage'],\n",
    "        metrics['tile_distribution']['Obstacle']['percentage'],\n",
    "        metrics['tile_distribution']['Platform']['percentage'],\n",
    "        metrics['tile_distribution']['Air']['percentage'],\n",
    "    ]\n",
    "    ax1.bar(x + (i * width), values, width, label=f\"Level {i+1}\")\n",
    "\n",
    "ax1.set_xlabel('Tile Type', fontweight='bold')\n",
    "ax1.set_ylabel('Percentage (%)', fontweight='bold')\n",
    "ax1.set_title('Tile Distribution Comparison', fontweight='bold')\n",
    "ax1.set_xticks(x + width)\n",
    "ax1.set_xticklabels(tile_types)\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Playability Metrics\n",
    "ax2 = axes[0, 1]\n",
    "metrics_names = ['Solid Density', 'Challenge', 'Collectibles']\n",
    "x2 = np.arange(len(evaluations))\n",
    "\n",
    "solid_density = [m['solid_tile_density'] for m in evaluations]\n",
    "challenge = [m['challenge_ratio'] for m in evaluations]\n",
    "collectibles = [m['collectible_ratio'] for m in evaluations]\n",
    "\n",
    "width2 = 0.25\n",
    "ax2.bar(x2 - width2, solid_density, width2, label='Solid Density', color='brown')\n",
    "ax2.bar(x2, challenge, width2, label='Challenge', color='red')\n",
    "ax2.bar(x2 + width2, collectibles, width2, label='Collectibles', color='gold')\n",
    "\n",
    "ax2.set_xlabel('Level', fontweight='bold')\n",
    "ax2.set_ylabel('Percentage (%)', fontweight='bold')\n",
    "ax2.set_title('Playability Metrics Comparison', fontweight='bold')\n",
    "ax2.set_xticks(x2)\n",
    "ax2.set_xticklabels([f\"L{i+1}\" for i in range(len(evaluations))])\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Coin and Obstacle Counts\n",
    "ax3 = axes[1, 0]\n",
    "coins = [m['coins'] for m in evaluations]\n",
    "obstacles = [m['obstacles'] for m in evaluations]\n",
    "x3 = np.arange(len(evaluations))\n",
    "\n",
    "ax3.bar(x3 - 0.2, coins, 0.4, label='Coins', color='gold')\n",
    "ax3.bar(x3 + 0.2, obstacles, 0.4, label='Obstacles', color='red')\n",
    "\n",
    "ax3.set_xlabel('Level', fontweight='bold')\n",
    "ax3.set_ylabel('Count', fontweight='bold')\n",
    "ax3.set_title('Coins vs Obstacles', fontweight='bold')\n",
    "ax3.set_xticks(x3)\n",
    "ax3.set_xticklabels([f\"L{i+1}\" for i in range(len(evaluations))])\n",
    "ax3.legend()\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: Summary Statistics\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "summary_text = \"SUMMARY STATISTICS\\n\" + \"=\"*30 + \"\\n\\n\"\n",
    "summary_text += f\"Total Levels Generated: {len(evaluations)}\\n\"\n",
    "summary_text += f\"Level Dimensions: {evaluations[0]['dimensions']}\\n\\n\"\n",
    "summary_text += \"Average Metrics:\\n\"\n",
    "summary_text += f\"  ‚Ä¢ Solid Density: {np.mean([m['solid_tile_density'] for m in evaluations]):.1f}%\\n\"\n",
    "summary_text += f\"  ‚Ä¢ Challenge: {np.mean([m['challenge_ratio'] for m in evaluations]):.1f}%\\n\"\n",
    "summary_text += f\"  ‚Ä¢ Collectibles: {np.mean([m['collectible_ratio'] for m in evaluations]):.1f}%\\n\"\n",
    "summary_text += f\"  ‚Ä¢ Avg Coins: {np.mean([m['coins'] for m in evaluations]):.1f}\\n\"\n",
    "summary_text += f\"  ‚Ä¢ Avg Obstacles: {np.mean([m['obstacles'] for m in evaluations]):.1f}\\n\"\n",
    "\n",
    "ax4.text(0.1, 0.5, summary_text, fontfamily='monospace', fontsize=11,\n",
    "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Comparative visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Export and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = os.path.join(os.getcwd(), 'generated_levels')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save level data and metrics\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save levels as numpy files\n",
    "for idx, level in enumerate(levels):\n",
    "    filename = os.path.join(results_dir, f'level_{idx+1}_{timestamp}.npy')\n",
    "    np.save(filename, level)\n",
    "    print(f\"‚úì Saved Level {idx+1} to {filename}\")\n",
    "\n",
    "# Save evaluation metrics as JSON\n",
    "metrics_filename = os.path.join(results_dir, f'metrics_{timestamp}.json')\n",
    "metrics_json = json.dumps(evaluations, indent=2, default=str)\n",
    "with open(metrics_filename, 'w') as f:\n",
    "    f.write(metrics_json)\nprint(f\"\\n‚úì Saved metrics to {metrics_filename}\")\n",
    "\n",
    "# Save comparison dataframe as CSV\n",
    "csv_filename = os.path.join(results_dir, f'comparison_{timestamp}.csv')\n",
    "df_comparison.to_csv(csv_filename, index=False)\nprint(f\"‚úì Saved comparison to {csv_filename}\")\n",
    "\n",
    "print(f\"\\n‚úì All results saved to {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë        MARIO GPT LEVEL GENERATION - EXECUTION SUMMARY          ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\n‚úÖ COMPLETED TASKS:\n   1. ‚úì Imported and initialized LevelGenerator\n   2. ‚úì Generated 3 procedural Mario levels\n   3. ‚úì Visualized all levels with color-coded tiles\n   4. ‚úì Evaluated level properties and metrics\n   5. ‚úì Performed comparative analysis\n   6. ‚úì Created detailed evaluation reports\n   7. ‚úì Generated comparison visualizations\n   8. ‚úì Exported results to files\n\nüìä GENERATION STATISTICS:\n   ‚Ä¢ Total Levels Generated: 3\n   ‚Ä¢ Level Dimensions: 16x50 (height x width)\n   ‚Ä¢ Total Tiles per Level: 800\n\nüéÆ PLAYABILITY INSIGHTS:\n   ‚Ä¢ Average Solid Density: {:.1f}%\n   ‚Ä¢ Average Challenge Ratio: {:.1f}%\n   ‚Ä¢ Average Collectible Ratio: {:.1f}%\n\nüìÅ OUTPUT ARTIFACTS:\n   ‚Ä¢ Generated Levels: {}/level_*.npy\n   ‚Ä¢ Metrics Data: {}/metrics_*.json\n   ‚Ä¢ Comparison CSV: {}/comparison_*.csv\n\nüöÄ NEXT STEPS:\n   1. Train a language model on level descriptions\n   2. Implement text-to-level generation\n   3. Integrate with game engine for playtesting\n   4. Fine-tune difficulty parameters\n   5. Develop level quality metrics\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\"\"\".format(\n    np.mean([m['solid_tile_density'] for m in evaluations]),\n    np.mean([m['challenge_ratio'] for m in evaluations]),\n    np.mean([m['collectible_ratio'] for m in evaluations]),\n    results_dir, results_dir, results_dir\n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: Custom Level Generation with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate custom level generation with different parameters\n",
    "print(\"\\nüé® CUSTOM LEVEL GENERATION\\n\")\nprint(\"Generating levels with different specifications...\\n\")\n",
    "\n",
    "# Create a larger level\n",
    "large_generator = LevelGenerator(width=80, height=20, seed=123)\n",
    "large_level = large_generator.generate(seed=123)\n",
    "\n",
    "print(f\"‚úì Large Level Generated: {large_level.shape}\")\nvisualize_level(large_level, title=\"Larger Generated Level (80x20 tiles)\", figsize=(20, 6))\nplt.show()\n",
    "\n",
    "# Evaluate the custom level\nmetrics_custom = evaluate_level(large_level, level_id=999)\nprint_level_report(metrics_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated:\n",
    "\n",
    "1. **Level Generation**: Using the LevelGenerator class to create procedurally-generated Mario levels\n",
    "2. **Visualization**: Displaying levels with intuitive color-coded tile representations\n",
    "3. **Evaluation**: Assessing levels using multiple metrics including structure, playability, and challenge\n",
    "4. **Analysis**: Comparing multiple levels and identifying patterns in generation\n",
    "5. **Export**: Saving generated data for further use\n",
    "\n",
    "The generated levels contain realistic Mario game elements (ground, platforms, coins, obstacles) and can be further refined using machine learning techniques to optimize for playability, challenge, and player engagement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}