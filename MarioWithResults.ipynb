{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravinds-kannappan/MarioGPT/blob/main/MarioWithResults.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMR7aZZ7Ywqr",
        "outputId": "2faed527-8b83-453c-fd4b-adb07a16fa20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarioGPT'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (165/165), done.\u001b[K\n",
            "remote: Total 165 (delta 62), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (165/165), 157.74 KiB | 6.86 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/aravinds-kannappan/MarioGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "HMM-DDA Complete Run Pipeline\n",
        "Unified script that imports and orchestrates all src/ and scripts/ modules.\n",
        "\n",
        "Usage:\n",
        "    python run_pipeline.py [--skip-calibration] [--episodes N] [--device cpu|cuda]\n",
        "\n",
        "Requires: src/ and scripts/ folders in the same directory\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from collections import deque, Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================================\n",
        "# PATH SETUP\n",
        "# ============================================================================\n",
        "# Ensure we point to the cloned repository\n",
        "PROJECT_ROOT = Path(\"/content/MarioGPT\")\n",
        "sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "print(\"Project root added:\", PROJECT_ROOT)\n",
        "\n",
        "# ============================================================================\n",
        "# IMPORTS\n",
        "# ============================================================================\n",
        "try:\n",
        "    from src.mario_env import MarioGridEnv\n",
        "    from src.level_generator import LevelGenerator\n",
        "    from src.hmm_controller import HMM_DDA\n",
        "    from src.metrics_collector import MetricsCollector\n",
        "    from src.t_score import (\n",
        "        compute_T_score,\n",
        "        compute_T_score_from_metrics,\n",
        "        get_metric_contributions,\n",
        "        interpret_T_score\n",
        "    )\n",
        "    from src.utils import (\n",
        "        Logger,\n",
        "        set_random_seeds,\n",
        "        check_cuda,\n",
        "        load_config,\n",
        "        save_config,\n",
        "        normalize_value,\n",
        "        denormalize_value,\n",
        "        plot_learning_curve,\n",
        "        plot_belief_evolution,\n",
        "        plot_state_distribution,\n",
        "        plot_metrics_comparison,\n",
        "        plot_t_score_distributions,\n",
        "        plot_state_transition_diagram,\n",
        "    )\n",
        "\n",
        "    from scripts.calibrate import (\n",
        "        HeuristicAgent,\n",
        "        GymEnvWrapper,\n",
        "        create_ppo_agent,\n",
        "        train_baseline_agent,\n",
        "        collect_calibration_data,\n",
        "    )\n",
        "\n",
        "    from scripts.derive_parameters import (\n",
        "        load_calibration_data,\n",
        "        compute_normalization_bounds,\n",
        "        compute_t_scores_for_episodes,\n",
        "        fit_gaussian_distributions,\n",
        "        derive_thresholds,\n",
        "        optimize_metric_weights,\n",
        "        create_transition_matrix,\n",
        "        visualize_distributions,\n",
        "    )\n",
        "\n",
        "    from scripts.train import (\n",
        "        CONFIG as TRAIN_CONFIG,\n",
        "        HeuristicAgent as TrainHeuristicAgent,\n",
        "        AdaptiveEnv,\n",
        "        create_ppo_agent as create_train_ppo_agent,\n",
        "        run_episode,\n",
        "    )\n",
        "\n",
        "    from scripts.evaluate import (\n",
        "        load_training_data,\n",
        "        compute_metrics_by_state,\n",
        "        generate_visualizations,\n",
        "        print_summary_statistics,\n",
        "    )\n",
        "except ImportError as e:\n",
        "    print(f\"\\nERROR: Could not import modules. Ensure {PROJECT_ROOT} contains 'src' and 'scripts' folders.\")\n",
        "    print(f\"Details: {e}\")\n",
        "    raise e\n",
        "\n",
        "# Check SB3 availability\n",
        "try:\n",
        "    from stable_baselines3 import PPO\n",
        "    from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "    SB3_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SB3_AVAILABLE = False\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "PIPELINE_CONFIG = {\n",
        "    'total_episodes': 1000,\n",
        "    'calibration_episodes_per_difficulty': 50,\n",
        "    'baseline_training_episodes': 200,\n",
        "    'hmm_update_frequency': 10,\n",
        "    'metrics_window': 10,\n",
        "    'checkpoint_frequency': 500,\n",
        "    'log_frequency': 50,\n",
        "    'max_steps_per_episode': 2000,\n",
        "    'adaptation_frequency': 500,\n",
        "    'train_freq': 10,\n",
        "    'train_timesteps': 2048,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 1: CALIBRATION\n",
        "# ============================================================================\n",
        "\n",
        "def phase1_calibration(generator: LevelGenerator, device: str, config: dict, output_dir: Path):\n",
        "    \"\"\"\n",
        "    Phase 1: Calibration\n",
        "    Imports and uses functions from scripts/calibrate.py\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 1: CALIBRATION\")\n",
        "    print(\"Using: scripts/calibrate.py\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    calibration_dir = output_dir / 'calibration_data'\n",
        "    calibration_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Step 1: Train baseline agent\n",
        "    print(\"\\nStep 1.1: Calling train_baseline_agent() from scripts/calibrate.py...\")\n",
        "    agent = train_baseline_agent(\n",
        "        generator=generator,\n",
        "        n_episodes=config['baseline_training_episodes'],\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Step 2: Collect calibration data\n",
        "    print(\"\\nStep 1.2: Calling collect_calibration_data() from scripts/calibrate.py...\")\n",
        "    calibration_results = {}\n",
        "\n",
        "    for difficulty in ['Low', 'Transition', 'High']:\n",
        "        df = collect_calibration_data(\n",
        "            agent=agent,\n",
        "            generator=generator,\n",
        "            difficulty_name=difficulty,\n",
        "            n_episodes=config['calibration_episodes_per_difficulty']\n",
        "        )\n",
        "\n",
        "        # Save to CSV\n",
        "        csv_path = calibration_dir / f'{difficulty.lower()}_metrics.csv'\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        calibration_results[difficulty] = df\n",
        "\n",
        "        print(f\"  {difficulty}: CR={df['completed'].mean():.2%}, Deaths={df['deaths'].mean():.2f}\")\n",
        "\n",
        "    print(f\"\\nCalibration data saved to {calibration_dir}\")\n",
        "    return calibration_results, agent\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 2: PARAMETER DERIVATION\n",
        "# ============================================================================\n",
        "\n",
        "def phase2_derive_parameters(calibration_dir: Path, output_dir: Path):\n",
        "    \"\"\"\n",
        "    Phase 2: Parameter Derivation\n",
        "    Imports and uses functions from scripts/derive_parameters.py\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 2: PARAMETER DERIVATION\")\n",
        "    print(\"Using: scripts/derive_parameters.py\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    config_dir = output_dir / 'config'\n",
        "    figures_dir = output_dir / 'figures' / 'calibration'\n",
        "    config_dir.mkdir(parents=True, exist_ok=True)\n",
        "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Step 2.1: Load calibration data\n",
        "    print(\"\\nStep 2.1: Calling load_calibration_data()...\")\n",
        "    data = load_calibration_data(calibration_dir)\n",
        "\n",
        "    # Step 2.2: Compute normalization bounds\n",
        "    print(\"\\nStep 2.2: Calling compute_normalization_bounds()...\")\n",
        "    normalization = compute_normalization_bounds(data)\n",
        "    save_config(normalization, str(config_dir / 'normalization_bounds.json'))\n",
        "\n",
        "    # Step 2.3: Optimize metric weights\n",
        "    print(\"\\nStep 2.3: Calling optimize_metric_weights()...\")\n",
        "    weights = optimize_metric_weights(data, normalization)\n",
        "    save_config({'weights': weights}, str(config_dir / 'metric_weights.json'))\n",
        "\n",
        "    # Step 2.4: Compute T-scores\n",
        "    print(\"\\nStep 2.4: Calling compute_t_scores_for_episodes()...\")\n",
        "    t_scores = compute_t_scores_for_episodes(data, weights, normalization)\n",
        "    for diff, scores in t_scores.items():\n",
        "        print(f\"  {diff}: mean={np.mean(scores):.3f}, std={np.std(scores):.3f}\")\n",
        "\n",
        "    # Step 2.5: Fit emission distributions\n",
        "    print(\"\\nStep 2.5: Calling fit_gaussian_distributions()...\")\n",
        "    emissions = fit_gaussian_distributions(t_scores)\n",
        "    save_config(emissions, str(config_dir / 'emission_params.json'))\n",
        "\n",
        "    # Step 2.6: Derive thresholds\n",
        "    print(\"\\nStep 2.6: Calling derive_thresholds()...\")\n",
        "    thresholds = derive_thresholds(emissions)\n",
        "    save_config(thresholds, str(config_dir / 'thresholds.json'))\n",
        "\n",
        "    # Step 2.7: Create transition matrix\n",
        "    print(\"\\nStep 2.7: Calling create_transition_matrix()...\")\n",
        "    transition_matrix = create_transition_matrix()\n",
        "    save_config(transition_matrix, str(config_dir / 'transition_matrix.json'))\n",
        "\n",
        "    # Step 2.8: Save prompts\n",
        "    prompts = {\n",
        "        'Low': \"few enemies, no gaps, many pipes, low elevation, easy\",\n",
        "        'Transition': \"varied challenges, mixed density, skill assessment\",\n",
        "        'High': \"many enemies, many gaps, few pipes, high elevation, hard\"\n",
        "    }\n",
        "    save_config(prompts, str(config_dir / 'prompts.json'))\n",
        "\n",
        "    # Step 2.9: Visualize\n",
        "    print(\"\\nStep 2.8: Calling visualize_distributions()...\")\n",
        "    visualize_distributions(t_scores, emissions, figures_dir)\n",
        "\n",
        "    print(f\"\\nParameters saved to {config_dir}\")\n",
        "\n",
        "    return {\n",
        "        'weights': weights,\n",
        "        'normalization': normalization,\n",
        "        'emissions': emissions,\n",
        "        'thresholds': thresholds,\n",
        "        'transition_matrix': transition_matrix,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 3: TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "def phase3_training(generator: LevelGenerator, device: str, config: dict,\n",
        "                    output_dir: Path, derived_params: dict):\n",
        "    \"\"\"\n",
        "    Phase 3: Training with HMM-DDA\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 3: TRAINING WITH HMM-DDA\")\n",
        "    print(\"Using: scripts/train.py, src/hmm_controller.py, src/metrics_collector.py\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    checkpoint_dir = output_dir / 'checkpoints'\n",
        "    log_dir = output_dir / 'logs'\n",
        "    config_dir = output_dir / 'config'\n",
        "\n",
        "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "    log_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Build T-score config\n",
        "    t_score_config = {\n",
        "        'weights': derived_params['weights'],\n",
        "        'normalization': derived_params['normalization']\n",
        "    }\n",
        "\n",
        "    # Initialize HMM_DDA\n",
        "    print(\"\\nInitializing HMM_DDA...\")\n",
        "    config_path = str(config_dir) if (config_dir / 'transition_matrix.json').exists() else None\n",
        "    hmm = HMM_DDA(config_path)\n",
        "    print(f\"  {hmm}\")\n",
        "\n",
        "    # Initialize AdaptiveEnv\n",
        "    print(\"\\nInitializing AdaptiveEnv...\")\n",
        "    env = AdaptiveEnv(generator, hmm)\n",
        "\n",
        "    # Create agent\n",
        "    print(f\"\\nCalling create_ppo_agent() (SB3: {SB3_AVAILABLE})...\")\n",
        "    agent = create_train_ppo_agent(env, device, TRAIN_CONFIG.get('ppo_config'))\n",
        "\n",
        "    # Initialize MetricsCollector\n",
        "    print(\"\\nInitializing MetricsCollector...\")\n",
        "    collector = MetricsCollector(max_size=2000, window_size=config['metrics_window'])\n",
        "\n",
        "    # Initialize Logger\n",
        "    print(\"Initializing Logger...\")\n",
        "    logger = Logger(str(log_dir), experiment_name='hmm_dda_training')\n",
        "\n",
        "    # Training statistics\n",
        "    episode_rewards = deque(maxlen=100)\n",
        "    state_counts = {'Low': 0, 'Transition': 0, 'High': 0}\n",
        "\n",
        "    print(f\"\\nStarting training loop...\")\n",
        "    print(f\"  Total episodes: {config['total_episodes']}\")\n",
        "\n",
        "    for episode in tqdm(range(config['total_episodes']), desc=\"Training\"):\n",
        "        current_state = hmm.get_current_state()\n",
        "        state_counts[current_state] += 1\n",
        "\n",
        "        # Run episode\n",
        "        metrics = run_episode(env, agent, max_steps=config['max_steps_per_episode'])\n",
        "\n",
        "        # Update collector\n",
        "        collector.add_episode(metrics)\n",
        "        episode_rewards.append(metrics['reward'])\n",
        "\n",
        "        # Update HMM periodically\n",
        "        if (episode + 1) % config['hmm_update_frequency'] == 0:\n",
        "            if len(collector) >= config['metrics_window']:\n",
        "                T = compute_T_score(collector, t_score_config, window=config['metrics_window'])\n",
        "                new_state = hmm.update(T)\n",
        "                belief = hmm.get_belief()\n",
        "\n",
        "                if new_state != current_state or (episode + 1) % config['log_frequency'] == 0:\n",
        "                    log_data = {\n",
        "                        'episode': episode + 1,\n",
        "                        'state': new_state,\n",
        "                        'prev_state': current_state,\n",
        "                        'belief_low': float(belief[0]),\n",
        "                        'belief_transition': float(belief[1]),\n",
        "                        'belief_high': float(belief[2]),\n",
        "                        'T_score': float(T),\n",
        "                        'reward': float(metrics['reward']),\n",
        "                        'avg_reward_100': float(np.mean(episode_rewards)),\n",
        "                        'completed': bool(metrics['completed']),\n",
        "                        'deaths': int(metrics['deaths']),\n",
        "                        'max_x': float(metrics['max_x']),\n",
        "                        'completion_rate': collector.get_completion_rate(),\n",
        "                    }\n",
        "                    logger.log(log_data, print_console=(episode + 1) % config['log_frequency'] == 0)\n",
        "\n",
        "        # Train PPO\n",
        "        if SB3_AVAILABLE and (episode + 1) % config['train_freq'] == 0:\n",
        "            agent.learn(total_timesteps=config['train_timesteps'], reset_num_timesteps=False)\n",
        "\n",
        "        # Checkpoint\n",
        "        if (episode + 1) % config['checkpoint_frequency'] == 0:\n",
        "            hmm.save_state(str(checkpoint_dir / f'hmm_{episode+1}.json'))\n",
        "            if SB3_AVAILABLE:\n",
        "                agent.save(str(checkpoint_dir / f'ppo_{episode+1}'))\n",
        "            collector.save_to_csv(str(checkpoint_dir / f'metrics_{episode+1}.csv'))\n",
        "\n",
        "            print(f\"\\n[Checkpoint {episode+1}]\")\n",
        "            print(f\"  State: {hmm.get_current_state()}, Belief: {hmm.get_belief().round(3)}\")\n",
        "            print(f\"  Avg Reward: {np.mean(episode_rewards):.2f}, CR: {collector.get_completion_rate():.2%}\")\n",
        "\n",
        "        # Adapt HMM\n",
        "        if (episode + 1) % config['adaptation_frequency'] == 0:\n",
        "            hmm.adapt_transition_matrix()\n",
        "\n",
        "    # Final save\n",
        "    hmm.save_state(str(checkpoint_dir / 'hmm_final.json'))\n",
        "    if SB3_AVAILABLE:\n",
        "        agent.save(str(checkpoint_dir / 'ppo_final'))\n",
        "    logger.save_metrics()\n",
        "    collector.save_to_csv(str(checkpoint_dir / 'metrics_final.csv'))\n",
        "    env.close()\n",
        "\n",
        "    print(f\"\\nTraining complete. Checkpoints saved to {checkpoint_dir}\")\n",
        "\n",
        "    return {\n",
        "        'hmm': hmm,\n",
        "        'collector': collector,\n",
        "        'state_counts': state_counts,\n",
        "        'final_avg_reward': float(np.mean(episode_rewards)),\n",
        "        'checkpoint_dir': checkpoint_dir,\n",
        "        'log_dir': log_dir,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 4: EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "def phase4_evaluation(training_results: dict, output_dir: Path):\n",
        "    \"\"\"\n",
        "    Phase 4: Evaluation\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 4: EVALUATION\")\n",
        "    print(\"Using: scripts/evaluate.py, src/utils.py\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    figures_dir = output_dir / 'figures' / 'evaluation'\n",
        "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    checkpoint_dir = training_results['checkpoint_dir']\n",
        "    log_dir = training_results['log_dir']\n",
        "    hmm = training_results['hmm']\n",
        "\n",
        "    print(\"\\nCalling load_training_data()...\")\n",
        "    metrics_df, hmm_data = load_training_data(checkpoint_dir, log_dir)\n",
        "\n",
        "    if not hmm_data:\n",
        "        hmm_data = {\n",
        "            'state_history': hmm.state_history,\n",
        "            'belief_history': [b.tolist() for b in hmm.belief_history],\n",
        "            't_score_history': hmm.t_score_history,\n",
        "        }\n",
        "\n",
        "    print(\"\\nCalling compute_metrics_by_state()...\")\n",
        "    metrics_by_state = compute_metrics_by_state(metrics_df, hmm_data)\n",
        "\n",
        "    print(\"\\nCalling generate_visualizations()...\")\n",
        "    generate_visualizations(metrics_df, hmm_data, figures_dir)\n",
        "\n",
        "    print(\"\\nCalling print_summary_statistics()...\")\n",
        "    print_summary_statistics(metrics_df, hmm_data, metrics_by_state)\n",
        "\n",
        "    if not metrics_df.empty and 'reward' in metrics_df.columns:\n",
        "        rewards = metrics_df['reward'].values\n",
        "        median_r = np.median(rewards)\n",
        "        std_r = np.std(rewards)\n",
        "        flow_min = median_r - 0.5 * std_r\n",
        "        flow_max = median_r + 0.5 * std_r\n",
        "        in_flow = np.sum((rewards >= flow_min) & (rewards <= flow_max))\n",
        "        flow_pct = in_flow / len(rewards) * 100\n",
        "        print(f\"\\nAdditional Flow Zone Analysis:\")\n",
        "        print(f\"  Flow zone: [{flow_min:.1f}, {flow_max:.1f}]\")\n",
        "        print(f\"  Episodes in flow: {in_flow}/{len(rewards)} ({flow_pct:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nFigures saved to {figures_dir}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def main(args=None):\n",
        "    if args is None:\n",
        "        parser = argparse.ArgumentParser(description='HMM-DDA Complete Pipeline')\n",
        "        parser.add_argument('--skip-calibration', action='store_true',\n",
        "                            help='Skip calibration and use default parameters')\n",
        "        parser.add_argument('--episodes', type=int, default=1000,\n",
        "                            help='Number of training episodes')\n",
        "        parser.add_argument('--calibration-episodes', type=int, default=50,\n",
        "                            help='Calibration episodes per difficulty')\n",
        "        parser.add_argument('--device', type=str, default='cpu', choices=['cpu', 'cuda'],\n",
        "                            help='Device for training')\n",
        "        parser.add_argument('--seed', type=int, default=42,\n",
        "                            help='Random seed')\n",
        "        parser.add_argument('--output-dir', type=str, default='./hmm_dda_output',\n",
        "                            help='Output directory')\n",
        "        args = parser.parse_args()\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"HMM-DDA COMPLETE PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Setup\n",
        "    set_random_seeds(args.seed)\n",
        "    cuda_available, device_name = check_cuda()\n",
        "    device = args.device if args.device == 'cpu' or cuda_available else 'cpu'\n",
        "    print(f\"\\nDevice: {device} ({device_name})\")\n",
        "    print(f\"SB3 Available: {SB3_AVAILABLE}\")\n",
        "\n",
        "    output_dir = Path(args.output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Update config\n",
        "    config = PIPELINE_CONFIG.copy()\n",
        "    config['total_episodes'] = args.episodes\n",
        "    config['calibration_episodes_per_difficulty'] = args.calibration_episodes\n",
        "    save_config(config, str(output_dir / 'run_config.json'))\n",
        "\n",
        "    # Initialize Generator\n",
        "    print(\"\\nInitializing LevelGenerator...\")\n",
        "    generator = LevelGenerator(device=device)\n",
        "\n",
        "    # Phases\n",
        "    if not args.skip_calibration:\n",
        "        phase1_calibration(generator, device, config, output_dir)\n",
        "        calibration_dir = output_dir / 'calibration_data'\n",
        "        derived_params = phase2_derive_parameters(calibration_dir, output_dir)\n",
        "    else:\n",
        "        print(\"\\nSkipping calibration, using default parameters...\")\n",
        "        config_dir = output_dir / 'config'\n",
        "        config_dir.mkdir(parents=True, exist_ok=True)\n",
        "        # Default parameters\n",
        "        derived_params = {\n",
        "            'weights': [0.25, 0.20, 0.25, 0.15, 0.15],\n",
        "            'normalization': {\n",
        "                'death_rate_max': 5.0,\n",
        "                'reward_trend_min': -50.0,\n",
        "                'reward_trend_max': 50.0,\n",
        "                'time_to_complete_max': 2000.0,\n",
        "                'progress_variance_max': 500.0,\n",
        "            },\n",
        "            'emissions': {\n",
        "                'Low': {'mu': 0.25, 'sigma': 0.15},\n",
        "                'Transition': {'mu': 0.50, 'sigma': 0.12},\n",
        "                'High': {'mu': 0.75, 'sigma': 0.15}\n",
        "            },\n",
        "            'thresholds': {'low_transition': 0.35, 'transition_high': 0.65},\n",
        "            'transition_matrix': {\n",
        "                'matrix': [[0.70, 0.25, 0.05], [0.20, 0.40, 0.40], [0.05, 0.25, 0.70]],\n",
        "                'states': ['Low', 'Transition', 'High'],\n",
        "            }\n",
        "        }\n",
        "        # Save defaults\n",
        "        save_config(derived_params['normalization'], str(config_dir / 'normalization_bounds.json'))\n",
        "        save_config({'weights': derived_params['weights']}, str(config_dir / 'metric_weights.json'))\n",
        "        save_config(derived_params['emissions'], str(config_dir / 'emission_params.json'))\n",
        "        save_config(derived_params['thresholds'], str(config_dir / 'thresholds.json'))\n",
        "        save_config(derived_params['transition_matrix'], str(config_dir / 'transition_matrix.json'))\n",
        "        save_config({\n",
        "            'Low': \"few enemies, no gaps, many pipes, low elevation, easy\",\n",
        "            'Transition': \"varied challenges, mixed density, skill assessment\",\n",
        "            'High': \"many enemies, many gaps, few pipes, high elevation, hard\"\n",
        "        }, str(config_dir / 'prompts.json'))\n",
        "\n",
        "    training_results = phase3_training(generator, device, config, output_dir, derived_params)\n",
        "    phase4_evaluation(training_results, output_dir)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PIPELINE COMPLETE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Notebook execution\n",
        "    try:\n",
        "        get_ipython()\n",
        "        print(\"Detected Notebook Environment.\")\n",
        "        class NotebookArgs:\n",
        "            skip_calibration = False\n",
        "            episodes = 500\n",
        "            calibration_episodes = 50\n",
        "            device = 'cpu'\n",
        "            seed = 42\n",
        "            output_dir = './hmm_dda_output'\n",
        "\n",
        "        main(NotebookArgs())\n",
        "    except NameError:\n",
        "        # Script execution\n",
        "        main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxefSv5D3Eiv",
        "outputId": "4a89d6ba-e642-40c5-b255-d19732f00d4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root added: /content/MarioGPT\n",
            "Detected Notebook Environment.\n",
            "============================================================\n",
            "HMM-DDA COMPLETE PIPELINE\n",
            "============================================================\n",
            "\n",
            "Device: cpu (NVIDIA A100-SXM4-80GB)\n",
            "SB3 Available: False\n",
            "\n",
            "Initializing LevelGenerator...\n",
            "MarioGPT not available - using procedural generation\n",
            "\n",
            "============================================================\n",
            "PHASE 1: CALIBRATION\n",
            "Using: scripts/calibrate.py\n",
            "============================================================\n",
            "\n",
            "Step 1.1: Calling train_baseline_agent() from scripts/calibrate.py...\n",
            "============================================================\n",
            "Training Baseline Agent on Mixed Difficulties\n",
            "============================================================\n",
            "Using heuristic agent (install stable-baselines3 for PPO)\n",
            "\n",
            "Step 1.2: Calling collect_calibration_data() from scripts/calibrate.py...\n",
            "\n",
            "Collecting 50 episodes for Low difficulty...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Low: 100%|██████████| 50/50 [00:00<00:00, 95.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Low: CR=56.00%, Deaths=0.62\n",
            "\n",
            "Collecting 50 episodes for Transition difficulty...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transition: 100%|██████████| 50/50 [00:00<00:00, 79.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Transition: CR=22.00%, Deaths=1.14\n",
            "\n",
            "Collecting 50 episodes for High difficulty...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "High: 100%|██████████| 50/50 [00:00<00:00, 75.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  High: CR=0.00%, Deaths=1.40\n",
            "\n",
            "Calibration data saved to hmm_dda_output/calibration_data\n",
            "\n",
            "============================================================\n",
            "PHASE 2: PARAMETER DERIVATION\n",
            "Using: scripts/derive_parameters.py\n",
            "============================================================\n",
            "\n",
            "Step 2.1: Calling load_calibration_data()...\n",
            "\n",
            "Step 2.2: Calling compute_normalization_bounds()...\n",
            "Normalization Bounds:\n",
            "  death_rate_max: 3.00\n",
            "  reward_min: -77.58\n",
            "  reward_max: 126.10\n",
            "  reward_trend_min: -50.00\n",
            "  reward_trend_max: 50.00\n",
            "  time_to_complete_max: 1000.00\n",
            "  progress_variance_max: 100.00\n",
            "\n",
            "Step 2.3: Calling optimize_metric_weights()...\n",
            "\n",
            "Optimizing Metric Weights...\n",
            "Optimized Weights:\n",
            "  CR: 0.000\n",
            "  DR: 0.089\n",
            "  RT: 0.368\n",
            "  TTC: 0.394\n",
            "  PV: 0.149\n",
            "\n",
            "Step 2.4: Calling compute_t_scores_for_episodes()...\n",
            "  low: mean=0.644, std=0.149\n",
            "  transition: mean=0.536, std=0.114\n",
            "  high: mean=0.476, std=0.015\n",
            "\n",
            "Step 2.5: Calling fit_gaussian_distributions()...\n",
            "\n",
            "Fitted Emission Distributions:\n",
            "  Low: μ=0.644, σ=0.149\n",
            "  Transition: μ=0.536, σ=0.114\n",
            "  High: μ=0.476, σ=0.050\n",
            "\n",
            "Step 2.6: Calling derive_thresholds()...\n",
            "\n",
            "Derived Thresholds:\n",
            "  Low → Transition: 0.644\n",
            "  Transition → High: 0.476\n",
            "\n",
            "Step 2.7: Calling create_transition_matrix()...\n",
            "\n",
            "Transition Matrix (Assessment State Design):\n",
            "[[0.7  0.25 0.05]\n",
            " [0.2  0.4  0.4 ]\n",
            " [0.05 0.25 0.7 ]]\n",
            "\n",
            "Key: Transition self-loop = 0.40 (quick assessment)\n",
            "\n",
            "Step 2.8: Calling visualize_distributions()...\n",
            "\n",
            "Saved visualization to hmm_dda_output/figures/calibration/tscore_distributions.png\n",
            "\n",
            "Parameters saved to hmm_dda_output/config\n",
            "\n",
            "============================================================\n",
            "PHASE 3: TRAINING WITH HMM-DDA\n",
            "Using: scripts/train.py, src/hmm_controller.py, src/metrics_collector.py\n",
            "============================================================\n",
            "\n",
            "Initializing HMM_DDA...\n",
            "Loaded HMM parameters from hmm_dda_output/config\n",
            "  HMM_DDA(state=Low, belief=[1.000, 0.000, 0.000])\n",
            "\n",
            "Initializing AdaptiveEnv...\n",
            "\n",
            "Calling create_ppo_agent() (SB3: False)...\n",
            "\n",
            "Initializing MetricsCollector...\n",
            "Initializing Logger...\n",
            "\n",
            "Starting training loop...\n",
            "  Total episodes: 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  13%|█▎        | 64/500 [00:00<00:03, 118.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode    50] State: Low        | Reward:   -54.00 | T-Score: 0.765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  20%|██        | 101/500 [00:01<00:04, 89.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode   100] State: Low        | Reward:   117.80 | T-Score: 0.801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  32%|███▏      | 159/500 [00:01<00:04, 74.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode   150] State: Low        | Reward:   118.40 | T-Score: 0.777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  43%|████▎     | 214/500 [00:02<00:03, 88.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode   200] State: Low        | Reward:   118.10 | T-Score: 0.735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  54%|█████▍    | 269/500 [00:03<00:01, 117.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode   250] State: Low        | Reward:   119.80 | T-Score: 0.757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  64%|██████▍   | 321/500 [00:03<00:01, 122.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode   300] State: Low        | Reward:   119.10 | T-Score: 0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  74%|███████▍  | 372/500 [00:04<00:01, 93.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode   350] State: Low        | Reward:   107.06 | T-Score: 0.761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  79%|███████▉  | 396/500 [00:04<00:01, 101.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode   400] State: Low        | Reward:   118.80 | T-Score: 0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  93%|█████████▎| 463/500 [00:05<00:00, 106.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode   450] State: Low        | Reward:   -54.40 | T-Score: 0.754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 500/500 [00:05<00:00, 88.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Episode   500] State: Low        | Reward:   -56.30 | T-Score: 0.776\n",
            "Saved 500 episodes to hmm_dda_output/checkpoints/metrics_500.csv\n",
            "\n",
            "[Checkpoint 500]\n",
            "  State: Low, Belief: [0.91 0.09 0.  ]\n",
            "  Avg Reward: 22.90, CR: 30.00%\n",
            "Saved 500 episodes to hmm_dda_output/checkpoints/metrics_final.csv\n",
            "\n",
            "Training complete. Checkpoints saved to hmm_dda_output/checkpoints\n",
            "\n",
            "============================================================\n",
            "PHASE 4: EVALUATION\n",
            "Using: scripts/evaluate.py, src/utils.py\n",
            "============================================================\n",
            "\n",
            "Calling load_training_data()...\n",
            "Loaded metrics from hmm_dda_output/checkpoints/metrics_final.csv\n",
            "Loaded HMM state from hmm_dda_output/checkpoints/hmm_final.json\n",
            "\n",
            "Calling compute_metrics_by_state()...\n",
            "Warning: state_history length (50) != metrics length (500)\n",
            "\n",
            "Calling generate_visualizations()...\n",
            "\n",
            "Generating visualizations...\n",
            "  ✓ Learning curve saved (no state coloring)\n",
            "  ✓ Belief evolution saved\n",
            "  ✓ State distribution saved\n",
            "Warning: state_history length (50) != metrics length (500)\n",
            "\n",
            "Calling print_summary_statistics()...\n",
            "\n",
            "============================================================\n",
            "Evaluation Summary\n",
            "============================================================\n",
            "\n",
            "Overall Performance:\n",
            "  Total episodes: 500\n",
            "  Completion rate: 53.40%\n",
            "  Average reward: 36.32\n",
            "  Reward std: 88.68\n",
            "  Average deaths: 0.60\n",
            "  Average max_x: 22.1\n",
            "\n",
            "State Distribution:\n",
            "  Low: 50 episodes (100.0%)\n",
            "  Transition: 0 episodes (0.0%)\n",
            "  High: 0 episodes (0.0%)\n",
            "\n",
            "Transition Frequency: 0.0 per 100 episodes\n",
            "\n",
            "Flow Zone Analysis (Section 7):\n",
            "  Flow zone: [69.3, 157.9]\n",
            "  Episodes in flow zone: 267 (53.4%)\n",
            "  Target: >60%\n",
            "  ✗ Below target by 6.6%\n",
            "\n",
            "Additional Flow Zone Analysis:\n",
            "  Flow zone: [69.3, 157.9]\n",
            "  Episodes in flow: 267/500 (53.4%)\n",
            "\n",
            "Figures saved to hmm_dda_output/figures/evaluation\n",
            "\n",
            "============================================================\n",
            "PIPELINE COMPLETE\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}