{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravinds-kannappan/MarioGPT/blob/main/Mario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMR7aZZ7Ywqr",
        "outputId": "5077a9d4-355a-4113-c64c-1dcf70539510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarioGPT'...\n",
            "remote: Enumerating objects: 132, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 132 (delta 40), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (132/132), 133.94 KiB | 3.52 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/aravinds-kannappan/MarioGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "HMM-DDA Complete Run Pipeline\n",
        "Unified script that imports and orchestrates all src/ and scripts/ modules.\n",
        "\n",
        "Usage:\n",
        "    python run_pipeline.py [--skip-calibration] [--episodes N] [--device cpu|cuda]\n",
        "\n",
        "Requires: src/ and scripts/ folders in the same directory\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Adjust this if needed\n",
        "PROJECT_ROOT = Path(\"/content/MarioGPT\")  # Colab example\n",
        "# PROJECT_ROOT = Path.cwd()               # if notebook is in root\n",
        "\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(\"Project root added:\", PROJECT_ROOT)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from collections import deque, Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================================\n",
        "# IMPORTS FROM src/ MODULES\n",
        "# ============================================================================\n",
        "from src.mario_env import MarioEnvWrapper, MarioGridEnv\n",
        "from src.level_generator import LevelGenerator\n",
        "from src.hmm_controller import HMM_DDA\n",
        "from src.metrics_collector import MetricsCollector\n",
        "from src.t_score import (\n",
        "    compute_T_score,\n",
        "    compute_T_score_from_metrics,\n",
        "    get_metric_contributions,\n",
        "    interpret_T_score\n",
        ")\n",
        "from src.utils import (\n",
        "    Logger,\n",
        "    set_random_seeds,\n",
        "    check_cuda,\n",
        "    load_config,\n",
        "    save_config,\n",
        "    normalize_value,\n",
        "    denormalize_value,\n",
        "    plot_learning_curve,\n",
        "    plot_belief_evolution,\n",
        "    plot_state_distribution,\n",
        "    plot_metrics_comparison,\n",
        "    plot_t_score_distributions,\n",
        "    plot_state_transition_diagram,\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# IMPORTS FROM scripts/ MODULES\n",
        "# ============================================================================\n",
        "from scripts.calibrate import (\n",
        "    HeuristicAgent,\n",
        "    GymEnvWrapper,\n",
        "    create_ppo_agent,\n",
        "    train_baseline_agent,\n",
        "    collect_calibration_data,\n",
        ")\n",
        "\n",
        "from scripts.derive_parameters import (\n",
        "    load_calibration_data,\n",
        "    compute_normalization_bounds,\n",
        "    compute_t_scores_for_episodes,\n",
        "    fit_gaussian_distributions,\n",
        "    derive_thresholds,\n",
        "    optimize_metric_weights,\n",
        "    create_transition_matrix,\n",
        "    visualize_distributions,\n",
        ")\n",
        "\n",
        "from scripts.train import (\n",
        "    CONFIG as TRAIN_CONFIG,\n",
        "    HeuristicAgent as TrainHeuristicAgent,\n",
        "    AdaptiveEnv,\n",
        "    create_ppo_agent as create_train_ppo_agent,\n",
        "    run_episode,\n",
        ")\n",
        "\n",
        "from scripts.evaluate import (\n",
        "    load_training_data,\n",
        "    compute_metrics_by_state,\n",
        "    generate_visualizations,\n",
        "    print_summary_statistics,\n",
        ")\n",
        "\n",
        "# Check SB3 availability\n",
        "try:\n",
        "    from stable_baselines3 import PPO\n",
        "    from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "    SB3_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SB3_AVAILABLE = False\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "PIPELINE_CONFIG = {\n",
        "    'total_episodes': 1000,\n",
        "    'calibration_episodes_per_difficulty': 50,\n",
        "    'baseline_training_episodes': 200,\n",
        "    'hmm_update_frequency': 10,\n",
        "    'metrics_window': 10,\n",
        "    'checkpoint_frequency': 500,\n",
        "    'log_frequency': 50,\n",
        "    'max_steps_per_episode': 2000,\n",
        "    'adaptation_frequency': 500,\n",
        "    'train_freq': 10,\n",
        "    'train_timesteps': 2048,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 1: CALIBRATION (using scripts/calibrate.py)\n",
        "# ============================================================================\n",
        "\n",
        "def phase1_calibration(generator: LevelGenerator, device: str, config: dict, output_dir: Path):\n",
        "    \"\"\"\n",
        "    Phase 1: Calibration\n",
        "    Imports and uses functions from scripts/calibrate.py:\n",
        "      - train_baseline_agent()\n",
        "      - collect_calibration_data()\n",
        "      - HeuristicAgent, GymEnvWrapper, create_ppo_agent\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 1: CALIBRATION\")\n",
        "    print(\"Using: scripts/calibrate.py\")\n",
        "    print(\"  - train_baseline_agent()\")\n",
        "    print(\"  - collect_calibration_data()\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    calibration_dir = output_dir / 'calibration_data'\n",
        "    calibration_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Step 1: Train baseline agent using calibrate.train_baseline_agent\n",
        "    print(\"\\nStep 1.1: Calling train_baseline_agent() from scripts/calibrate.py...\")\n",
        "    agent = train_baseline_agent(\n",
        "        generator=generator,\n",
        "        n_episodes=config['baseline_training_episodes'],\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Step 2: Collect calibration data using calibrate.collect_calibration_data\n",
        "    print(\"\\nStep 1.2: Calling collect_calibration_data() from scripts/calibrate.py...\")\n",
        "    calibration_results = {}\n",
        "\n",
        "    for difficulty in ['Low', 'Transition', 'High']:\n",
        "        df = collect_calibration_data(\n",
        "            agent=agent,\n",
        "            generator=generator,\n",
        "            difficulty_name=difficulty,\n",
        "            n_episodes=config['calibration_episodes_per_difficulty']\n",
        "        )\n",
        "\n",
        "        # Save to CSV\n",
        "        csv_path = calibration_dir / f'{difficulty.lower()}_metrics.csv'\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        calibration_results[difficulty] = df\n",
        "\n",
        "        print(f\"  {difficulty}: CR={df['completed'].mean():.2%}, Deaths={df['deaths'].mean():.2f}\")\n",
        "\n",
        "    print(f\"\\nCalibration data saved to {calibration_dir}\")\n",
        "    return calibration_results, agent\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 2: PARAMETER DERIVATION (using scripts/derive_parameters.py)\n",
        "# ============================================================================\n",
        "\n",
        "def phase2_derive_parameters(calibration_dir: Path, output_dir: Path):\n",
        "    \"\"\"\n",
        "    Phase 2: Parameter Derivation\n",
        "    Imports and uses functions from scripts/derive_parameters.py:\n",
        "      - load_calibration_data()\n",
        "      - compute_normalization_bounds()\n",
        "      - optimize_metric_weights()\n",
        "      - compute_t_scores_for_episodes()\n",
        "      - fit_gaussian_distributions()\n",
        "      - derive_thresholds()\n",
        "      - create_transition_matrix()\n",
        "      - visualize_distributions()\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 2: PARAMETER DERIVATION\")\n",
        "    print(\"Using: scripts/derive_parameters.py\")\n",
        "    print(\"  - load_calibration_data()\")\n",
        "    print(\"  - compute_normalization_bounds()\")\n",
        "    print(\"  - optimize_metric_weights()\")\n",
        "    print(\"  - fit_gaussian_distributions()\")\n",
        "    print(\"  - derive_thresholds()\")\n",
        "    print(\"  - create_transition_matrix()\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    config_dir = output_dir / 'config'\n",
        "    figures_dir = output_dir / 'figures' / 'calibration'\n",
        "    config_dir.mkdir(parents=True, exist_ok=True)\n",
        "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Step 2.1: Load calibration data\n",
        "    print(\"\\nStep 2.1: Calling load_calibration_data()...\")\n",
        "    data = load_calibration_data(calibration_dir)\n",
        "\n",
        "    # Step 2.2: Compute normalization bounds\n",
        "    print(\"\\nStep 2.2: Calling compute_normalization_bounds()...\")\n",
        "    normalization = compute_normalization_bounds(data)\n",
        "    save_config(normalization, str(config_dir / 'normalization_bounds.json'))\n",
        "\n",
        "    # Step 2.3: Optimize metric weights\n",
        "    print(\"\\nStep 2.3: Calling optimize_metric_weights()...\")\n",
        "    weights = optimize_metric_weights(data, normalization)\n",
        "    save_config({'weights': weights}, str(config_dir / 'metric_weights.json'))\n",
        "\n",
        "    # Step 2.4: Compute T-scores\n",
        "    print(\"\\nStep 2.4: Calling compute_t_scores_for_episodes()...\")\n",
        "    t_scores = compute_t_scores_for_episodes(data, weights, normalization)\n",
        "    for diff, scores in t_scores.items():\n",
        "        print(f\"  {diff}: mean={np.mean(scores):.3f}, std={np.std(scores):.3f}\")\n",
        "\n",
        "    # Step 2.5: Fit emission distributions\n",
        "    print(\"\\nStep 2.5: Calling fit_gaussian_distributions()...\")\n",
        "    emissions = fit_gaussian_distributions(t_scores)\n",
        "    save_config(emissions, str(config_dir / 'emission_params.json'))\n",
        "\n",
        "    # Step 2.6: Derive thresholds\n",
        "    print(\"\\nStep 2.6: Calling derive_thresholds()...\")\n",
        "    thresholds = derive_thresholds(emissions)\n",
        "    save_config(thresholds, str(config_dir / 'thresholds.json'))\n",
        "\n",
        "    # Step 2.7: Create transition matrix\n",
        "    print(\"\\nStep 2.7: Calling create_transition_matrix()...\")\n",
        "    transition_matrix = create_transition_matrix()\n",
        "    save_config(transition_matrix, str(config_dir / 'transition_matrix.json'))\n",
        "\n",
        "    # Step 2.8: Save prompts\n",
        "    prompts = {\n",
        "        'Low': \"few enemies, no gaps, many pipes, low elevation, easy\",\n",
        "        'Transition': \"varied challenges, mixed density, skill assessment\",\n",
        "        'High': \"many enemies, many gaps, few pipes, high elevation, hard\"\n",
        "    }\n",
        "    save_config(prompts, str(config_dir / 'prompts.json'))\n",
        "\n",
        "    # Step 2.9: Visualize\n",
        "    print(\"\\nStep 2.8: Calling visualize_distributions()...\")\n",
        "    visualize_distributions(t_scores, emissions, figures_dir)\n",
        "\n",
        "    print(f\"\\nParameters saved to {config_dir}\")\n",
        "\n",
        "    return {\n",
        "        'weights': weights,\n",
        "        'normalization': normalization,\n",
        "        'emissions': emissions,\n",
        "        'thresholds': thresholds,\n",
        "        'transition_matrix': transition_matrix,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 3: TRAINING (using scripts/train.py and src/ modules)\n",
        "# ============================================================================\n",
        "\n",
        "def phase3_training(generator: LevelGenerator, device: str, config: dict,\n",
        "                    output_dir: Path, derived_params: dict):\n",
        "    \"\"\"\n",
        "    Phase 3: Training with HMM-DDA\n",
        "    Imports and uses from scripts/train.py:\n",
        "      - TRAIN_CONFIG\n",
        "      - AdaptiveEnv\n",
        "      - create_ppo_agent()\n",
        "      - run_episode()\n",
        "\n",
        "    Also uses from src/:\n",
        "      - HMM_DDA (src/hmm_controller.py)\n",
        "      - MetricsCollector (src/metrics_collector.py)\n",
        "      - compute_T_score (src/t_score.py)\n",
        "      - Logger (src/utils.py)\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 3: TRAINING WITH HMM-DDA\")\n",
        "    print(\"Using: scripts/train.py\")\n",
        "    print(\"  - AdaptiveEnv\")\n",
        "    print(\"  - create_ppo_agent()\")\n",
        "    print(\"  - run_episode()\")\n",
        "    print(\"Using: src/hmm_controller.py\")\n",
        "    print(\"  - HMM_DDA\")\n",
        "    print(\"Using: src/metrics_collector.py\")\n",
        "    print(\"  - MetricsCollector\")\n",
        "    print(\"Using: src/t_score.py\")\n",
        "    print(\"  - compute_T_score()\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    checkpoint_dir = output_dir / 'checkpoints'\n",
        "    log_dir = output_dir / 'logs'\n",
        "    config_dir = output_dir / 'config'\n",
        "\n",
        "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "    log_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Build T-score config for src/t_score.py\n",
        "    t_score_config = {\n",
        "        'weights': derived_params['weights'],\n",
        "        'normalization': derived_params['normalization']\n",
        "    }\n",
        "\n",
        "    # Initialize HMM_DDA from src/hmm_controller.py\n",
        "    print(\"\\nInitializing HMM_DDA from src/hmm_controller.py...\")\n",
        "    config_path = str(config_dir) if (config_dir / 'transition_matrix.json').exists() else None\n",
        "    hmm = HMM_DDA(config_path)\n",
        "    print(f\"  {hmm}\")\n",
        "\n",
        "    # Initialize AdaptiveEnv from scripts/train.py\n",
        "    print(\"\\nInitializing AdaptiveEnv from scripts/train.py...\")\n",
        "    env = AdaptiveEnv(generator, hmm)\n",
        "\n",
        "    # Create agent using scripts/train.py create_ppo_agent\n",
        "    print(f\"\\nCalling create_ppo_agent() from scripts/train.py (SB3: {SB3_AVAILABLE})...\")\n",
        "    agent = create_train_ppo_agent(env, device, TRAIN_CONFIG.get('ppo_config'))\n",
        "\n",
        "    # Initialize MetricsCollector from src/metrics_collector.py\n",
        "    print(\"\\nInitializing MetricsCollector from src/metrics_collector.py...\")\n",
        "    collector = MetricsCollector(max_size=2000, window_size=config['metrics_window'])\n",
        "\n",
        "    # Initialize Logger from src/utils.py\n",
        "    print(\"Initializing Logger from src/utils.py...\")\n",
        "    logger = Logger(str(log_dir), experiment_name='hmm_dda_training')\n",
        "\n",
        "    # Training statistics\n",
        "    episode_rewards = deque(maxlen=100)\n",
        "    state_counts = {'Low': 0, 'Transition': 0, 'High': 0}\n",
        "\n",
        "    print(f\"\\nStarting training loop...\")\n",
        "    print(f\"  Total episodes: {config['total_episodes']}\")\n",
        "    print(f\"  HMM update frequency: {config['hmm_update_frequency']}\")\n",
        "\n",
        "    for episode in tqdm(range(config['total_episodes']), desc=\"Training\"):\n",
        "        # Get current state from HMM_DDA\n",
        "        current_state = hmm.get_current_state()\n",
        "        state_counts[current_state] += 1\n",
        "\n",
        "        # Run episode using scripts/train.py run_episode()\n",
        "        metrics = run_episode(env, agent, max_steps=config['max_steps_per_episode'])\n",
        "\n",
        "        # Add to MetricsCollector from src/metrics_collector.py\n",
        "        collector.add_episode(metrics)\n",
        "        episode_rewards.append(metrics['reward'])\n",
        "\n",
        "        # Update HMM periodically using src/t_score.py compute_T_score\n",
        "        if (episode + 1) % config['hmm_update_frequency'] == 0:\n",
        "            if len(collector) >= config['metrics_window']:\n",
        "                # Compute T-score using src/t_score.py\n",
        "                T = compute_T_score(collector, t_score_config, window=config['metrics_window'])\n",
        "\n",
        "                # Update HMM belief using src/hmm_controller.py\n",
        "                new_state = hmm.update(T)\n",
        "                belief = hmm.get_belief()\n",
        "\n",
        "                if new_state != current_state or (episode + 1) % config['log_frequency'] == 0:\n",
        "                    log_data = {\n",
        "                        'episode': episode + 1,\n",
        "                        'state': new_state,\n",
        "                        'prev_state': current_state,\n",
        "                        'belief_low': float(belief[0]),\n",
        "                        'belief_transition': float(belief[1]),\n",
        "                        'belief_high': float(belief[2]),\n",
        "                        'T_score': float(T),\n",
        "                        'reward': float(metrics['reward']),\n",
        "                        'avg_reward_100': float(np.mean(episode_rewards)),\n",
        "                        'completed': bool(metrics['completed']),\n",
        "                        'deaths': int(metrics['deaths']),\n",
        "                        'max_x': float(metrics['max_x']),\n",
        "                        'completion_rate': collector.get_completion_rate(),\n",
        "                    }\n",
        "                    # Log using src/utils.py Logger\n",
        "                    logger.log(log_data, print_console=(episode + 1) % config['log_frequency'] == 0)\n",
        "\n",
        "        # Train PPO agent\n",
        "        if SB3_AVAILABLE and (episode + 1) % config['train_freq'] == 0:\n",
        "            agent.learn(total_timesteps=config['train_timesteps'], reset_num_timesteps=False)\n",
        "\n",
        "        # Checkpoint\n",
        "        if (episode + 1) % config['checkpoint_frequency'] == 0:\n",
        "            # Save HMM state using src/hmm_controller.py\n",
        "            hmm.save_state(str(checkpoint_dir / f'hmm_{episode+1}.json'))\n",
        "            if SB3_AVAILABLE:\n",
        "                agent.save(str(checkpoint_dir / f'ppo_{episode+1}'))\n",
        "            # Save metrics using src/metrics_collector.py\n",
        "            collector.save_to_csv(str(checkpoint_dir / f'metrics_{episode+1}.csv'))\n",
        "\n",
        "            print(f\"\\n[Checkpoint {episode+1}]\")\n",
        "            print(f\"  State: {hmm.get_current_state()}, Belief: {hmm.get_belief().round(3)}\")\n",
        "            print(f\"  Avg Reward: {np.mean(episode_rewards):.2f}, CR: {collector.get_completion_rate():.2%}\")\n",
        "\n",
        "        # Adapt HMM using src/hmm_controller.py\n",
        "        if (episode + 1) % config['adaptation_frequency'] == 0:\n",
        "            hmm.adapt_transition_matrix()\n",
        "\n",
        "    # Final save\n",
        "    hmm.save_state(str(checkpoint_dir / 'hmm_final.json'))\n",
        "    if SB3_AVAILABLE:\n",
        "        agent.save(str(checkpoint_dir / 'ppo_final'))\n",
        "    logger.save_metrics()\n",
        "    collector.save_to_csv(str(checkpoint_dir / 'metrics_final.csv'))\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    print(f\"\\nTraining complete. Checkpoints saved to {checkpoint_dir}\")\n",
        "\n",
        "    return {\n",
        "        'hmm': hmm,\n",
        "        'collector': collector,\n",
        "        'state_counts': state_counts,\n",
        "        'final_avg_reward': float(np.mean(episode_rewards)),\n",
        "        'checkpoint_dir': checkpoint_dir,\n",
        "        'log_dir': log_dir,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 4: EVALUATION (using scripts/evaluate.py and src/utils.py)\n",
        "# ============================================================================\n",
        "\n",
        "def phase4_evaluation(training_results: dict, output_dir: Path):\n",
        "    \"\"\"\n",
        "    Phase 4: Evaluation\n",
        "    Imports and uses from scripts/evaluate.py:\n",
        "      - load_training_data()\n",
        "      - compute_metrics_by_state()\n",
        "      - generate_visualizations()\n",
        "      - print_summary_statistics()\n",
        "\n",
        "    Also uses from src/utils.py:\n",
        "      - plot_learning_curve()\n",
        "      - plot_belief_evolution()\n",
        "      - plot_state_distribution()\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 4: EVALUATION\")\n",
        "    print(\"Using: scripts/evaluate.py\")\n",
        "    print(\"  - load_training_data()\")\n",
        "    print(\"  - compute_metrics_by_state()\")\n",
        "    print(\"  - generate_visualizations()\")\n",
        "    print(\"  - print_summary_statistics()\")\n",
        "    print(\"Using: src/utils.py\")\n",
        "    print(\"  - plot_learning_curve()\")\n",
        "    print(\"  - plot_belief_evolution()\")\n",
        "    print(\"  - plot_state_distribution()\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    figures_dir = output_dir / 'figures' / 'evaluation'\n",
        "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    checkpoint_dir = training_results['checkpoint_dir']\n",
        "    log_dir = training_results['log_dir']\n",
        "    hmm = training_results['hmm']\n",
        "    state_counts = training_results['state_counts']\n",
        "\n",
        "    # Load training data using scripts/evaluate.py load_training_data()\n",
        "    print(\"\\nCalling load_training_data() from scripts/evaluate.py...\")\n",
        "    metrics_df, hmm_data = load_training_data(checkpoint_dir, log_dir)\n",
        "\n",
        "    # If hmm_data is empty, use the HMM from training\n",
        "    if not hmm_data:\n",
        "        hmm_data = {\n",
        "            'state_history': hmm.state_history,\n",
        "            'belief_history': [b.tolist() for b in hmm.belief_history],\n",
        "            't_score_history': hmm.t_score_history,\n",
        "        }\n",
        "\n",
        "    # Compute metrics by state using scripts/evaluate.py compute_metrics_by_state()\n",
        "    print(\"\\nCalling compute_metrics_by_state() from scripts/evaluate.py...\")\n",
        "    metrics_by_state = compute_metrics_by_state(metrics_df, hmm_data)\n",
        "\n",
        "    # Generate visualizations using scripts/evaluate.py generate_visualizations()\n",
        "    print(\"\\nCalling generate_visualizations() from scripts/evaluate.py...\")\n",
        "    generate_visualizations(metrics_df, hmm_data, figures_dir)\n",
        "\n",
        "    # Print summary using scripts/evaluate.py print_summary_statistics()\n",
        "    print(\"\\nCalling print_summary_statistics() from scripts/evaluate.py...\")\n",
        "    print_summary_statistics(metrics_df, hmm_data, metrics_by_state)\n",
        "\n",
        "    # Additional: Flow zone analysis\n",
        "    if not metrics_df.empty and 'reward' in metrics_df.columns:\n",
        "        rewards = metrics_df['reward'].values\n",
        "        median_r = np.median(rewards)\n",
        "        std_r = np.std(rewards)\n",
        "        flow_min = median_r - 0.5 * std_r\n",
        "        flow_max = median_r + 0.5 * std_r\n",
        "\n",
        "        in_flow = np.sum((rewards >= flow_min) & (rewards <= flow_max))\n",
        "        flow_pct = in_flow / len(rewards) * 100\n",
        "\n",
        "        print(f\"\\nAdditional Flow Zone Analysis:\")\n",
        "        print(f\"  Flow zone: [{flow_min:.1f}, {flow_max:.1f}]\")\n",
        "        print(f\"  Episodes in flow: {in_flow}/{len(rewards)} ({flow_pct:.1f}%)\")\n",
        "        print(f\"  Target: >60%  {'✓ ACHIEVED' if flow_pct >= 60 else '✗ Below target'}\")\n",
        "\n",
        "    print(f\"\\nFigures saved to {figures_dir}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='HMM-DDA Complete Pipeline')\n",
        "    parser.add_argument('--skip-calibration', action='store_true',\n",
        "                        help='Skip calibration and use default parameters')\n",
        "    parser.add_argument('--episodes', type=int, default=1000,\n",
        "                        help='Number of training episodes')\n",
        "    parser.add_argument('--calibration-episodes', type=int, default=50,\n",
        "                        help='Calibration episodes per difficulty')\n",
        "    parser.add_argument('--device', type=str, default='cpu', choices=['cpu', 'cuda'],\n",
        "                        help='Device for training')\n",
        "    parser.add_argument('--seed', type=int, default=42,\n",
        "                        help='Random seed')\n",
        "    parser.add_argument('--output-dir', type=str, default='./hmm_dda_output',\n",
        "                        help='Output directory')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"HMM-DDA COMPLETE PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nImported modules:\")\n",
        "    print(\"  src/mario_env.py         -> MarioEnvWrapper, MarioGridEnv\")\n",
        "    print(\"  src/level_generator.py   -> LevelGenerator\")\n",
        "    print(\"  src/hmm_controller.py    -> HMM_DDA\")\n",
        "    print(\"  src/metrics_collector.py -> MetricsCollector\")\n",
        "    print(\"  src/t_score.py           -> compute_T_score, compute_T_score_from_metrics\")\n",
        "    print(\"  src/utils.py             -> Logger, plotting functions, etc.\")\n",
        "    print(\"  scripts/calibrate.py     -> train_baseline_agent, collect_calibration_data\")\n",
        "    print(\"  scripts/derive_parameters.py -> load_calibration_data, fit_gaussian_distributions, etc.\")\n",
        "    print(\"  scripts/train.py         -> AdaptiveEnv, run_episode, create_ppo_agent\")\n",
        "    print(\"  scripts/evaluate.py      -> load_training_data, generate_visualizations, etc.\")\n",
        "\n",
        "    # Setup using src/utils.py\n",
        "    set_random_seeds(args.seed)\n",
        "    cuda_available, device_name = check_cuda()\n",
        "    device = args.device if args.device == 'cpu' or cuda_available else 'cpu'\n",
        "    print(f\"\\nDevice: {device} ({device_name})\")\n",
        "    print(f\"SB3 Available: {SB3_AVAILABLE}\")\n",
        "\n",
        "    output_dir = Path(args.output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Update config\n",
        "    config = PIPELINE_CONFIG.copy()\n",
        "    config['total_episodes'] = args.episodes\n",
        "    config['calibration_episodes_per_difficulty'] = args.calibration_episodes\n",
        "\n",
        "    # Save config using src/utils.py\n",
        "    save_config(config, str(output_dir / 'run_config.json'))\n",
        "\n",
        "    # Initialize LevelGenerator from src/level_generator.py\n",
        "    print(\"\\nInitializing LevelGenerator from src/level_generator.py...\")\n",
        "    generator = LevelGenerator(device=device)\n",
        "\n",
        "    # ========================================================================\n",
        "    # PHASE 1 & 2: Calibration and Parameter Derivation\n",
        "    # ========================================================================\n",
        "    if not args.skip_calibration:\n",
        "        # Phase 1: Calibration (scripts/calibrate.py)\n",
        "        calibration_results, baseline_agent = phase1_calibration(\n",
        "            generator, device, config, output_dir\n",
        "        )\n",
        "\n",
        "        # Phase 2: Parameter Derivation (scripts/derive_parameters.py)\n",
        "        calibration_dir = output_dir / 'calibration_data'\n",
        "        derived_params = phase2_derive_parameters(calibration_dir, output_dir)\n",
        "    else:\n",
        "        print(\"\\nSkipping calibration, using default parameters...\")\n",
        "        config_dir = output_dir / 'config'\n",
        "        config_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Default parameters\n",
        "        derived_params = {\n",
        "            'weights': [0.25, 0.20, 0.25, 0.15, 0.15],\n",
        "            'normalization': {\n",
        "                'death_rate_max': 5.0,\n",
        "                'reward_trend_min': -50.0,\n",
        "                'reward_trend_max': 50.0,\n",
        "                'time_to_complete_max': 2000.0,\n",
        "                'progress_variance_max': 500.0,\n",
        "            },\n",
        "            'emissions': {\n",
        "                'Low': {'mu': 0.25, 'sigma': 0.15},\n",
        "                'Transition': {'mu': 0.50, 'sigma': 0.12},\n",
        "                'High': {'mu': 0.75, 'sigma': 0.15}\n",
        "            },\n",
        "            'thresholds': {'low_transition': 0.35, 'transition_high': 0.65},\n",
        "            'transition_matrix': {\n",
        "                'matrix': [[0.70, 0.25, 0.05], [0.20, 0.40, 0.40], [0.05, 0.25, 0.70]],\n",
        "                'states': ['Low', 'Transition', 'High'],\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Save using src/utils.py save_config\n",
        "        save_config(derived_params['normalization'], str(config_dir / 'normalization_bounds.json'))\n",
        "        save_config({'weights': derived_params['weights']}, str(config_dir / 'metric_weights.json'))\n",
        "        save_config(derived_params['emissions'], str(config_dir / 'emission_params.json'))\n",
        "        save_config(derived_params['thresholds'], str(config_dir / 'thresholds.json'))\n",
        "        save_config(derived_params['transition_matrix'], str(config_dir / 'transition_matrix.json'))\n",
        "        save_config({\n",
        "            'Low': \"few enemies, no gaps, many pipes, low elevation, easy\",\n",
        "            'Transition': \"varied challenges, mixed density, skill assessment\",\n",
        "            'High': \"many enemies, many gaps, few pipes, high elevation, hard\"\n",
        "        }, str(config_dir / 'prompts.json'))\n",
        "\n",
        "    # ========================================================================\n",
        "    # PHASE 3: Training (scripts/train.py + src/ modules)\n",
        "    # ========================================================================\n",
        "    training_results = phase3_training(generator, device, config, output_dir, derived_params)\n",
        "\n",
        "    # ========================================================================\n",
        "    # PHASE 4: Evaluation (scripts/evaluate.py + src/utils.py)\n",
        "    # ========================================================================\n",
        "    phase4_evaluation(training_results, output_dir)\n",
        "\n",
        "    # ========================================================================\n",
        "    # FINAL SUMMARY\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PIPELINE COMPLETE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nOutput directory: {output_dir}\")\n",
        "    print(f\"  config/           - HMM parameters (from scripts/derive_parameters.py)\")\n",
        "    print(f\"  calibration_data/ - Calibration metrics (from scripts/calibrate.py)\")\n",
        "    print(f\"  checkpoints/      - Model checkpoints (from scripts/train.py)\")\n",
        "    print(f\"  logs/             - Training logs (from src/utils.py Logger)\")\n",
        "    print(f\"  figures/          - Visualizations (from scripts/evaluate.py + src/utils.py)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODULE USAGE SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nsrc/ modules used:\")\n",
        "    print(\"  ✓ src/mario_env.py         - MarioEnvWrapper, MarioGridEnv\")\n",
        "    print(\"  ✓ src/level_generator.py   - LevelGenerator\")\n",
        "    print(\"  ✓ src/hmm_controller.py    - HMM_DDA (Bayesian updates, state tracking)\")\n",
        "    print(\"  ✓ src/metrics_collector.py - MetricsCollector (episode buffering)\")\n",
        "    print(\"  ✓ src/t_score.py           - compute_T_score, interpret_T_score\")\n",
        "    print(\"  ✓ src/utils.py             - Logger, plotting, config I/O\")\n",
        "\n",
        "    print(\"\\nscripts/ modules used:\")\n",
        "    print(\"  ✓ scripts/calibrate.py         - train_baseline_agent, collect_calibration_data\")\n",
        "    print(\"  ✓ scripts/derive_parameters.py - Parameter fitting and optimization\")\n",
        "    print(\"  ✓ scripts/train.py             - AdaptiveEnv, run_episode, training loop\")\n",
        "    print(\"  ✓ scripts/evaluate.py          - Visualization and summary statistics\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "hxefSv5D3Eiv",
        "outputId": "96f80dce-8bb9-46e7-ff53-0cd4616cae58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root added: /content/MarioGPT\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'mario_env_wrapper' from partially initialized module 'src' (most likely due to a circular import) (/content/MarioGPT/src/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4179143517.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# IMPORTS FROM src/ MODULES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# ============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmario_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarioEnvWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMarioGridEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLevelGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhmm_controller\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHMM_DDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MarioGPT/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhmm_controller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlevel_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmario_env_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m __all__ = [\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'mario_env_wrapper' from partially initialized module 'src' (most likely due to a circular import) (/content/MarioGPT/src/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}